{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"ollama simple app\"\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ddde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9760234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Translate this text into {language} you do not have to specify any kind of information in english just translate \"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee4169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd45421",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a878c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、私の名前はアヌージです。\n"
     ]
    }
   ],
   "source": [
    "res = chain.invoke({\"language\":\"japanese\", \"input\":\"hello my name is anuj\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ebb421",
   "metadata": {},
   "source": [
    "## simple GenAI app that can remember with sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6d484",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a404ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store = {} # this stores all the session id\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240c7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75cd0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b12415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Anuj! Nice to meet you! That's great to hear that you're learning about General AI (Gen AI). It's an exciting and rapidly evolving field that has the potential to revolutionize many aspects of our lives.\\n\\nWhat specific areas of Gen AI are you most interested in learning about? Are you exploring topics like machine learning, natural language processing, computer vision, or something else?\\n\\nAlso, what's your current level of experience with Gen AI? Are you just starting out, or do you have some background knowledge that you're looking to build upon? I'm here to help and provide guidance as you continue your learning journey!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 129, 'prompt_tokens': 48, 'total_tokens': 177, 'completion_time': 0.282763294, 'prompt_time': 0.00238686, 'queue_time': 0.052695016000000004, 'total_time': 0.285150154}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--19fbd657-fcf2-4e72-b85c-15cd5194f2f8-0', usage_metadata={'input_tokens': 48, 'output_tokens': 129, 'total_tokens': 177})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am anuj. i am currently learning gen AI\"),\n",
    "     ],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b20897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Anuj, and you are currently learning about General AI (Gen AI).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 202, 'total_tokens': 221, 'completion_time': 0.05415137, 'prompt_time': 0.010063712, 'queue_time': 0.052049557999999996, 'total_time': 0.064215082}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--25fbc479-87b4-4d4f-8e1c-457480ee4550-0', usage_metadata={'input_tokens': 202, 'output_tokens': 19, 'total_tokens': 221})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name? and do you know what i am learning right now?\"),\n",
    "     ],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ab374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name. I'm a large language model, I don't have the ability to recall personal information about individuals, and our conversation just started. I'm happy to chat with you, though! If you'd like to share your name, I'd be happy to use it in our conversation.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 43, 'total_tokens': 110, 'completion_time': 0.146074977, 'prompt_time': 0.002578847, 'queue_time': 0.051620853, 'total_time': 0.148653824}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d80dcf43-6504-4ec5-a281-45170f1566f6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 67, 'total_tokens': 110})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_2 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, do you know my name?\"),\n",
    "     ],config=config_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fa8fc",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5766c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the nest of your ability, I want you to answer in this {language}.\",),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd341396",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8d42b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config3 = {\"configurable\":{\"session_id\":\"chat_6\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95d95453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Konnichiwa Anuj-san!)\\n\\n\\n(Anata wa Anuj desu ne?)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = with_message_history.invoke({\n",
    "    \"message\":[HumanMessage(content=\"Hi i am anuj.\")],\"language\":\"japanese\"\n",
    "},\n",
    "config=config3\n",
    ")\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94d43fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Anata no namae wa Anuj desu.)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = with_message_history.invoke({\n",
    "    \"message\":[HumanMessage(content=\"what is my name\")],\"language\":\"japanese\"\n",
    "},\n",
    "config=config3\n",
    ")\n",
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55360c5",
   "metadata": {},
   "source": [
    "## Managing the conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e857ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
