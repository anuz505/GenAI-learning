{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"ollama simple app\"\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ddde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9760234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Translate this text into {language} you do not have to specify any kind of information in english just translate \"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee4169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd45421",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a878c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、私の名前はアヌジュです\n"
     ]
    }
   ],
   "source": [
    "res = chain.invoke({\"language\":\"japanese\", \"input\":\"hello my name is anuj\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ebb421",
   "metadata": {},
   "source": [
    "## simple GenAI app that can remember with sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6d484",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a404ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store = {} # this stores all the session id\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240c7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75cd0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b12415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Anuj, nice to meet you. That's great to hear that you're learning about General AI (Gen AI). It's an exciting and rapidly evolving field that has the potential to transform many aspects of our lives.\\n\\nWhat specific areas of Gen AI are you interested in or currently learning about? Are you exploring topics like natural language processing, computer vision, reinforcement learning, or something else?\\n\\nAlso, what's your background and what motivated you to learn about Gen AI? Are you looking to apply your knowledge in a particular industry or domain? I'm here to help and provide any guidance or resources I can.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 48, 'total_tokens': 172, 'completion_time': 0.333705232, 'prompt_time': 0.00237133, 'queue_time': 0.056452020000000006, 'total_time': 0.336076562}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4728f18c-c7f8-4bdc-be3c-ea348c74d1fb-0', usage_metadata={'input_tokens': 48, 'output_tokens': 124, 'total_tokens': 172})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am anuj. i am currently learning gen AI\"),\n",
    "     ],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b20897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Anuj, and according to our conversation, you are currently learning about General AI (Gen AI).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 197, 'total_tokens': 221, 'completion_time': 0.083806183, 'prompt_time': 0.009890477, 'queue_time': 0.052817353000000004, 'total_time': 0.09369666}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--513a1db7-73ef-4572-aeec-bc4c198baeb3-0', usage_metadata={'input_tokens': 197, 'output_tokens': 24, 'total_tokens': 221})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name? and do you know what i am learning right now?\"),\n",
    "     ],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ab374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name. I'm a large language model, I don't have the ability to recall previous conversations or maintain personal information about users. Each time you interact with me, it's a new conversation. If you'd like to share your name, I'd be happy to chat with you and address you by name!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 43, 'total_tokens': 114, 'completion_time': 0.141565267, 'prompt_time': 0.002615213, 'queue_time': 0.052159057, 'total_time': 0.14418048}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5cff803f-8c09-4929-a3b9-c36c34320eaf-0', usage_metadata={'input_tokens': 43, 'output_tokens': 71, 'total_tokens': 114})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_2 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, do you know my name?\"),\n",
    "     ],config=config_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fa8fc",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5766c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the nest of your ability, I want you to answer in this {language}.\",),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd341396",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d42b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config3 = {\"configurable\":{\"session_id\":\"chat_6\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95d95453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(konnichiwa) Anuj-san, watashi wa anata no shitsumon ni kotaete ikimasu. Nihongo de hanasou to omoimasu ka? (Hello Anuj, I'll do my best to answer your questions. Shall we converse in Japanese?)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = with_message_history.invoke({\n",
    "    \"message\":[HumanMessage(content=\"Hi i am anuj.\")],\"language\":\"japanese\"\n",
    "},\n",
    "config=config3\n",
    ")\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94d43fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(anata no namae wa) Anuj desu ne. (Your name is Anuj, isn't it?)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = with_message_history.invoke({\n",
    "    \"message\":[HumanMessage(content=\"what is my name\")],\"language\":\"japanese\"\n",
    "},\n",
    "config=config3\n",
    ")\n",
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55360c5",
   "metadata": {},
   "source": [
    "## Managing the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef6ce5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages, AIMessage\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a30c19",
   "metadata": {},
   "source": [
    "The chain is set up to assign messages using itemgetter, retrieve them from the prompt template, and apply the trimmer. The chain is then concatenated with the prompt and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(message = itemgetter(\"message\")| trimmer)\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df7f0bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know, you didn't tell me! This is the start of our conversation, I don't have any information about your favorite ice cream. Want to share?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"message\": messages + [HumanMessage(content=\"what ice cream did i like ?\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "673ad6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked for the answer to 2 + 2.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"message\": messages + [HumanMessage(content=\"what math problem did i ask for ?\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2240d",
   "metadata": {},
   "source": [
    "## Wraping it all in a message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b42d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")\n",
    "config = {\"configurable\":{\"session_id\":\"chat_6\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35dccc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked what 2 + 2 is.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"message\":messages + [HumanMessage(content=\"do you know what math problem did i ask?\")],\n",
    "        \"language\":\"english\"\n",
    "    },\n",
    "    config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a842dc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We\\'ve had a few conversations so far. Here\\'s a summary:\\n\\n* You mentioned that you like vanilla ice cream.\\n* You asked me a math question, \"what\\'s 2 + 2\", and I replied that the answer is 4.\\n* You thanked me for answering your question.\\n* You asked if I was having fun, and I said yes.\\n* Now, you\\'re asking me to tell you about our conversations, which I\\'m doing!\\n\\nIt\\'s been a nice and simple conversation so far! Is there anything else you\\'d like to talk about?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"message\":messages + [HumanMessage(content=\"tell me about our conversations\")],\n",
    "        \"language\":\"english\"\n",
    "    },\n",
    "    config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca3e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
